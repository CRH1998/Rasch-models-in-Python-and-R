{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to Python 3.11.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b51e2417-2d4e-4c2a-b785-31dcbb610db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "#                                      Importing relevant libraries                                     #\n",
    "#########################################################################################################\n",
    "\n",
    "import pandas as pd                 # For data manipulation\n",
    "import numpy as np                  # For numerical operations\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor # For parallel processing\n",
    "\n",
    "import matplotlib.pyplot as plt     # For plotting\n",
    "import seaborn as sns               # For plotting\n",
    "\n",
    "\n",
    "import sys, os                      # For adding the RaschPy library to the path\n",
    "\n",
    "sys.path.append(os.path.abspath(\"C:/Users/brf337/Desktop/Rasch package/RaschPy/RaschPy\"))\n",
    "import __init__ as Rasch # Loading the RaschPy library\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "#                                      Rasch plot functions                                             #\n",
    "#########################################################################################################\n",
    "\n",
    "def plot_item_data(data):\n",
    "    \"\"\"\n",
    "    Plot the histograms of the the responses stratified by item.\n",
    "    \"\"\"\n",
    "    # Initialize an empty dictionary to store the counts\n",
    "    counts = {}\n",
    "    for column in data.columns:\n",
    "        counts[column] = data[column].value_counts()\n",
    "\n",
    "    # Restructure the dictionary to be orded by item\n",
    "    counts_dataframe = pd.DataFrame(counts)\n",
    "\n",
    "    # Plot the counts as a bar chart ordered by items for each item and display in a grid\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(20, 10))\n",
    "    axes = axes.ravel()\n",
    "    for i, (column, items) in enumerate(counts_dataframe.items()):\n",
    "        items.plot(kind='bar', ax=axes[i])\n",
    "        axes[i].set_title(f'{column}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_person_data(data):\n",
    "    \"\"\"\n",
    "    Plot the person abilities as a histogram.\n",
    "    \"\"\"\n",
    "    # Plot the person abilities as a histogram\n",
    "    data.plot(kind='hist', bins=30)\n",
    "    plt.title('Person Abilities')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_person_score_data(data):\n",
    "    \"\"\"\n",
    "    Plot the person scores against the person abilities.\n",
    "    \"\"\"\n",
    "    # Plot the person scores against the person abilities\n",
    "    data.plot(kind='scatter', x='Abilities', y='SumScores')\n",
    "    plt.title('Person Scores vs Abilities')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_person_score_data_score_est(data, ability_est):\n",
    "    \"\"\"\n",
    "    Plot the person scores against the person abilities and for each score the estimated ability.\n",
    "    \"\"\"\n",
    "    # Plot the person scores against the person abilities\n",
    "    data.plot(kind='scatter', x='Abilities', y='SumScores')\n",
    "    plt.plot(ability_est['Estimate'], ability_est['Score'], 'ro')\n",
    "    plt.title('Person Scores vs Abilities')\n",
    "    plt.show()\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################################################################################### \n",
    "#                                         PCM simulation function                                       #\n",
    "#########################################################################################################\n",
    "\n",
    "def simulate_PCM(k, n, manual_diffs, manual_abilities, PCM_options=5, item_response_to_add = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to simulate a Partial Credit Model (PCM) dataset from a dichotomous Rasch dataset.\n",
    "\n",
    "    Arguments:\n",
    "    k: int, the number of items\n",
    "    n: int, the number of persons\n",
    "    PCM_options: int, the number of answer options in the PCM model\n",
    "    manual_diffs: list, the manual difficulties of the items\n",
    "    manual_abilities: list, the manual abilities of the persons\n",
    "    item_response_to_add: list, which items to add together from the dichotomous Rasch dataset\n",
    "\n",
    "    Returns:\n",
    "    PCM_df: DataFrame, the PCM dataset\n",
    "    \"\"\"\n",
    "\n",
    "    # Simulate the dichotomous Rasch dataset\n",
    "    SML_Sims = Rasch.SLM_Sim(\n",
    "        no_of_items=k, no_of_persons=n,\n",
    "        manual_diffs=manual_diffs,\n",
    "        manual_abilities=manual_abilities\n",
    "    )\n",
    "    SML_df = SML_Sims.scores\n",
    "\n",
    "\n",
    "    if item_response_to_add is None:\n",
    "        PCM_df = SML_df.groupby([[i//PCM_options for i in range(0, len(SML_df.columns))]], axis = 1).sum()\n",
    "\n",
    "        # Change the column names to item_1, item_2, ...\n",
    "        PCM_df.columns = ['Item_' + str(i+1) for i in range(0, len(PCM_df.columns))]\n",
    "\n",
    "\n",
    "    else:\n",
    "        # Create empty pandas dataframe with number of columns of item_response_to_add and number of rows of SML_df\n",
    "        PCM_df = pd.DataFrame(index = range(0, len(SML_df)), columns = range(0, len(item_response_to_add)))\n",
    "\n",
    "        for i in range(0, len(item_response_to_add)):\n",
    "            PCM_df[i] = np.array(SML_df[item_response_to_add[i]].sum(axis = 1))\n",
    "\n",
    "        # Change the column names to item_1, item_2, ...\n",
    "        PCM_df.columns = ['Item_' + str(i+1) for i in range(0, len(PCM_df.columns))]\n",
    "\n",
    "\n",
    "    return PCM_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "\n",
    "######################################################################################################### \n",
    "#                                      Rasch simulation study functions                                 #\n",
    "#########################################################################################################\n",
    "\n",
    "def simulate_SML_iteration(n_persons, k_items, manual_diffs, manual_abilities):\n",
    "    \"\"\"\n",
    "    This function runs a single iteration of dichotomous Rasch simulation study.\n",
    "    The function returns the estimated item difficulties, the standard deviations of the estimated item difficulties,\n",
    "    and whethere the confidence interval contains the true parameter.\n",
    "    \n",
    "    Arguments:\n",
    "    n_persons: int, the number of persons\n",
    "    k: int, the number of items\n",
    "    manual_diffs: list, the manual difficulties of the items\n",
    "    manual_abilities: list, the manual abilities of the persons\n",
    "    \n",
    "    Returns:\n",
    "    estimates: list, the estimated item difficulties\n",
    "    ses: list, the standard deviations of the estimated item difficulties\n",
    "    coverage_bool: list, whether the confidence interval contains the true parameter\n",
    "    \"\"\"\n",
    "    SML_Sims = Rasch.SLM_Sim(\n",
    "        no_of_items=k_items, no_of_persons=n_persons,\n",
    "        manual_diffs=manual_diffs,\n",
    "        manual_abilities=manual_abilities\n",
    "    )\n",
    "    RaschBinaryTestSim = Rasch.SLM(SML_Sims.scores)\n",
    "    RaschBinaryTestSim.item_stats_df()\n",
    "\n",
    "    item_stats = RaschBinaryTestSim.item_stats\n",
    "    estimates = item_stats[\"Estimate\"].values\n",
    "    ses = item_stats[\"SE\"].values\n",
    "    lower_CI = estimates - ses * 1.96\n",
    "    upper_CI = estimates + ses * 1.96\n",
    "    coverage_bool = (lower_CI < manual_diffs) & (upper_CI > manual_diffs)\n",
    "\n",
    "    return estimates, ses, coverage_bool\n",
    "\n",
    "\n",
    "def run_SML_simulation_study(n_simulations, n_persons, k_items, manual_diffs, manual_abilities):\n",
    "    \"\"\"\n",
    "    This function runs a simulation study for dichotomous Rasch model. In particular it runs the simulate_iteration function\n",
    "    in parallel for n_simulations times and aggregates the results.\n",
    "\n",
    "    Arguments:\n",
    "    n_simulations: int, the number of simulations\n",
    "    n_persons: int, the number of persons\n",
    "    k_items: int, the number of items\n",
    "    manual_diffs: list, the manual difficulties of the items\n",
    "    manual_abilities: list, the manual abilities of the persons\n",
    "\n",
    "    Returns:\n",
    "    diffculties_est_df: DataFrame, the estimated item difficulties for each simulation\n",
    "    diffculties_sd_df: DataFrame, the standard deviations of the estimated item difficulties for each simulation\n",
    "    diffculties_est_mean: list, the mean of the estimated item difficulties\n",
    "    difficulties_est_sd: list, the standard deviation of the estimated item difficulties\n",
    "    diffculties_sd_mean: list, the mean of the standard deviations of the estimated item difficulties\n",
    "    coverage: list, the coverage of the 95% confidence intervals for the item difficulties\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    diffculties_est_list = []\n",
    "    diffculties_sd_list = []\n",
    "    coverage_array = np.zeros(k_items)\n",
    "\n",
    "    # Use parallel processing for the simulations\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results = list(executor.map(\n",
    "            simulate_SML_iteration,\n",
    "            [n_persons] * n_simulations,\n",
    "            [k_items] * n_simulations,\n",
    "            [manual_diffs] * n_simulations,\n",
    "            [manual_abilities] * n_simulations\n",
    "        ))\n",
    "\n",
    "    for estimates, ses, coverage_bool in results:\n",
    "        diffculties_est_list.append(estimates)\n",
    "        diffculties_sd_list.append(ses)\n",
    "        coverage_array += coverage_bool\n",
    "\n",
    "    # Convert lists to DataFrames for easier aggregation\n",
    "    diffculties_est_df = pd.DataFrame(diffculties_est_list)\n",
    "    diffculties_sd_df = pd.DataFrame(diffculties_sd_list)\n",
    "\n",
    "    # Aggregate results\n",
    "    diffculties_est_mean = diffculties_est_df.mean(axis=0)\n",
    "    difficulties_est_sd = diffculties_est_df.std(axis=0)\n",
    "    diffculties_sd_mean = diffculties_sd_df.mean(axis=0)\n",
    "    coverage = coverage_array / n_simulations\n",
    "\n",
    "    return (\n",
    "        diffculties_est_df,\n",
    "        diffculties_sd_df,\n",
    "        diffculties_est_mean,\n",
    "        difficulties_est_sd,\n",
    "        diffculties_sd_mean,\n",
    "        coverage\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "#                                      Dichotomize data                                                 #\n",
    "#########################################################################################################\n",
    "\n",
    "def dichotomize_data(data, threshold, column_names):\n",
    "    \"\"\"\n",
    "    This function dichotomizes the specified columns of the data based on a threshold.\n",
    "    \n",
    "    Arguments:\n",
    "    data: DataFrame, the data to dichotomize\n",
    "    threshold: float, the threshold to dichotomize the data\n",
    "    column_names: list, the columns to dichotomize\n",
    "    \n",
    "    Returns:\n",
    "    data_dichotomized: DataFrame, the dichotomized data\n",
    "    \"\"\"\n",
    "    \n",
    "    data_dichotomized = data.copy()\n",
    "    for column in column_names:\n",
    "        data_dichotomized[column] = data[column] > threshold\n",
    "        data_dichotomized[column] = data_dichotomized[column].astype(int)\n",
    "\n",
    "    return data_dichotomized\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "#                               Rasch model fit simulation data                                         #\n",
    "#########################################################################################################\n",
    "\n",
    "\n",
    "def run_one_InfitOutfit(n_persons, k_items, manual_diffs = None, manual_abilities = None, misspecified_items = None):\n",
    "    \"\"\"\n",
    "    This function runs a single iteration of Rasch model fit simulation study.\n",
    "    The function returns the maximum and minimum infit and outfit statistics for each item.\n",
    "    \n",
    "    Arguments:\n",
    "    n_persons: int, the number of persons\n",
    "    k: int, the number of items\n",
    "    manual_diffs: list, the manual difficulties of the items\n",
    "    manual_abilities: list, the manual abilities of the persons\n",
    "    misspecified_items: list, the items to misspecify\n",
    "    \n",
    "    Returns:\n",
    "    infit_outfit_stats: DataFrame, the infit and outfit statistics for each item\n",
    "    \"\"\"\n",
    "    \n",
    "    # Simulate the dichotomous Rasch dataset\n",
    "\n",
    "    if manual_diffs is None:\n",
    "        if manual_abilities is None:\n",
    "            SML_Sims = Rasch.SLM_Sim(\n",
    "                no_of_items=k_items, \n",
    "                no_of_persons=n_persons\n",
    "            )\n",
    "        else:\n",
    "            SML_Sims = Rasch.SLM_Sim(\n",
    "                no_of_items=k_items, \n",
    "                no_of_persons=n_persons,\n",
    "                manual_abilities=manual_abilities\n",
    "            )\n",
    "    else:\n",
    "        if manual_abilities is None:\n",
    "            SML_Sims = Rasch.SLM_Sim(\n",
    "                no_of_items=k_items, \n",
    "                no_of_persons=n_persons,\n",
    "                manual_diffs=manual_diffs\n",
    "            )\n",
    "        else:\n",
    "            SML_Sims = Rasch.SLM_Sim(\n",
    "                no_of_items=k_items, \n",
    "                no_of_persons=n_persons,\n",
    "                manual_diffs=manual_diffs,\n",
    "                manual_abilities=manual_abilities\n",
    "            )\n",
    "\n",
    "    \n",
    "    # Misspecify the items\n",
    "    if misspecified_items is not None:\n",
    "        for item in misspecified_items:\n",
    "            SML_Sims.scores[item] = np.random.randint(0, 2, n_persons)\n",
    "    \n",
    "    RaschBinaryTestSim = Rasch.SLM(SML_Sims.scores)\n",
    "    RaschBinaryTestSim.item_stats_df()\n",
    "    \n",
    "    infit_outfit_stats_max = RaschBinaryTestSim.item_stats[['Infit MS', 'Outfit MS']].max()\n",
    "    infit_outfit_stats_min = RaschBinaryTestSim.item_stats[['Infit MS', 'Outfit MS']].min()\n",
    "    \n",
    "    return [[infit_outfit_stats_max, infit_outfit_stats_min]]\n",
    "\n",
    "\n",
    "\n",
    "def run_InfitOutfit_simulation_study(n_simulations, n_persons, k_items, manual_diffs = None, manual_abilities = None, misspecified_items = None):\n",
    "    \"\"\"\n",
    "    This function runs a simulation study for Rasch model fit. In particular it runs the run_one_InfitOutfit function\n",
    "    in parallel for n_simulations times and aggregates the results.\n",
    "    \n",
    "    Arguments:\n",
    "    n_simulations: int, the number of simulations\n",
    "    n_persons: int, the number of persons\n",
    "    k_items: int, the number of items\n",
    "    manual_diffs: list, the manual difficulties of the items\n",
    "    manual_abilities: list, the manual abilities of the persons\n",
    "    misspecified_items: list, the items to misspecify\n",
    "    \n",
    "    Returns:\n",
    "    infit_outfit_stats_max: DataFrame, the maximum infit and outfit statistics for each item\n",
    "    infit_outfit_stats_min: DataFrame, the minimum infit and outfit statistics for each item\n",
    "    \"\"\"\n",
    "    \n",
    "    infit_outfit_stats_max = pd.DataFrame()\n",
    "    infit_outfit_stats_min = pd.DataFrame()\n",
    "    \n",
    "    # Use parallel processing for the simulations\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results = list(executor.map(\n",
    "            run_one_InfitOutfit,\n",
    "            [n_persons] * n_simulations,\n",
    "            [k_items] * n_simulations,\n",
    "            [manual_diffs] * n_simulations,\n",
    "            [manual_abilities] * n_simulations,\n",
    "            [misspecified_items] * n_simulations\n",
    "        ))\n",
    "    \n",
    "    for result in results:\n",
    "        infit_outfit_stats_max = pd.concat([infit_outfit_stats_max, pd.DataFrame(result[0][0])], axis = 0)\n",
    "        infit_outfit_stats_min = pd.concat([infit_outfit_stats_min, pd.DataFrame(result[0][1])], axis = 0)\n",
    "    \n",
    "    return infit_outfit_stats_max, infit_outfit_stats_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Infit MS     1.066\n",
       "  Outfit MS    1.099\n",
       "  dtype: float64,\n",
       "  Infit MS     0.798\n",
       "  Outfit MS    0.692\n",
       "  dtype: float64]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_one_InfitOutfit(n_persons=100, k_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\queues.py\", line 246, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\connection.py\", line 184, in send_bytes\n",
      "    self._check_closed()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\connection.py\", line 137, in _check_closed\n",
      "    raise OSError(\"handle is closed\")\n",
      "OSError: handle is closed\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun_InfitOutfit_simulation_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_simulations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_persons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 379\u001b[0m, in \u001b[0;36mrun_InfitOutfit_simulation_study\u001b[1;34m(n_simulations, n_persons, k_items, manual_diffs, manual_abilities, misspecified_items)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;66;03m# Use parallel processing for the simulations\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m--> 379\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_one_InfitOutfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mn_persons\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_simulations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mk_items\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_simulations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmanual_diffs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_simulations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmanual_abilities\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_simulations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmisspecified_items\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_simulations\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m    389\u001b[0m     infit_outfit_stats_max \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([infit_outfit_stats_max, pd\u001b[38;5;241m.\u001b[39mDataFrame(result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\process.py:620\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[1;34m(iterable)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[0;32m    615\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;124;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;124;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;124;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43melement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwhile\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "run_InfitOutfit_simulation_study(n_simulations=2, n_persons=100, k_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(               0\n",
       " Infit MS   0.980\n",
       " Outfit MS  1.119\n",
       " Infit MS   0.977\n",
       " Outfit MS  0.969,\n",
       "                0\n",
       " Infit MS   0.867\n",
       " Outfit MS  0.748\n",
       " Infit MS   0.877\n",
       " Outfit MS  0.777)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_InfitOutfit_simulation_study(n_simulations=2, n_persons=500, k_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(               0\n",
       " Infit MS   1.011\n",
       " Outfit MS  0.978\n",
       " Infit MS   0.974\n",
       " Outfit MS  0.950,\n",
       "                0\n",
       " Infit MS   0.900\n",
       " Outfit MS  0.797\n",
       " Infit MS   0.903\n",
       " Outfit MS  0.838)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_InfitOutfit_simulation_study(n_simulations=2, n_persons=1000, k_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(               0\n",
       " Infit MS   0.978\n",
       " Outfit MS  0.983\n",
       " Infit MS   0.976\n",
       " Outfit MS  0.957,\n",
       "                0\n",
       " Infit MS   0.890\n",
       " Outfit MS  0.822\n",
       " Infit MS   0.871\n",
       " Outfit MS  0.827)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_InfitOutfit_simulation_study(n_simulations=2, n_persons=1000, k_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(               0\n",
       " Infit MS   1.180\n",
       " Outfit MS  1.367\n",
       " Infit MS   1.108\n",
       " Outfit MS  1.153,\n",
       "                0\n",
       " Infit MS   0.740\n",
       " Outfit MS  0.652\n",
       " Infit MS   0.739\n",
       " Outfit MS  0.676)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_InfitOutfit_simulation_study(n_simulations=2, n_persons=100, k_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Infit MS     1.063\n",
       "  Outfit MS    1.245\n",
       "  dtype: float64,\n",
       "  Infit MS     0.795\n",
       "  Outfit MS    0.521\n",
       "  dtype: float64]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_one_InfitOutfit(n_persons=100, k_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Infit MS     1.095\n",
       "  Outfit MS    1.130\n",
       "  dtype: float64,\n",
       "  Infit MS     0.825\n",
       "  Outfit MS    0.692\n",
       "  dtype: float64]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_one_InfitOutfit(n_persons=100, k_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Infit MS     1.195\n",
       "  Outfit MS    1.244\n",
       "  dtype: float64,\n",
       "  Infit MS     0.725\n",
       "  Outfit MS    0.634\n",
       "  dtype: float64]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_one_InfitOutfit(n_persons=100, k_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Infit MS     1.136\n",
       "  Outfit MS    1.395\n",
       "  dtype: float64,\n",
       "  Infit MS     0.815\n",
       "  Outfit MS    0.711\n",
       "  dtype: float64]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_one_InfitOutfit(n_persons=100, k_items=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
